# Real-time Behaviour Recognition on a Surveillance Drone

Project: FIT3161/FIT3162 Computer Science Project
<br>Group: MCS23
<br>Contributors: Lim Yun Feng, Ting Yi Xuan, Chua Sheen Wey 
<br>Year: 2023

## Launch User Application / Model Inference
The following modules are used for starting the application and perform the behaviour recognition in run-time:
* <i>main.py</i>: Main entry point of the application and the main window of the application
* <i>strean_thread.py</i>: A worker thread that captures frames from a video source and performs inference on them.
* <i>pose_detector.py</i>: PoseDetector class used to detect the pose of a person in a video frame.
* <i>inference.py</i>: The inference logic for the application.
* <i>video_source.py</i>: Webcam, Drone and PreRecorded classes, which are the different video sources used by the application.
* <i>utils.py</i>: Functions and constants used by other modules in the system.
<br>
<br>

The following are the steps to launch the application:

1. Download the folder or clone the repository

2. Navigate to the directory

3. Install the dependencies.
    ```
    pip3 install -r requirements.txt
    ```

4. Start the application by running the following command:
    ```
    python ./main.py
    ```
    Note: The application may take a few minutes to launch.

5. Select the preferred configuration in the application and click on the start stream button. 

    Note: The streaming may take a few seconds to start after the message "Streaming is in progress ..." appears.

## Testing
The following are the modules used for testing various functionalities of the application and the behaviour recognition model:
* <i>test_draw.py</i>: Test the functions used to draw the output of the behaviour recognition model.
* <i>test_human_tracking.py</i>: Test the human-tracking model.
* <i>test_pose_estimation.py</i>: Test the pose estimation model.
* <i>test_action_recognition.py</i>: Test the action recognition model.
<br>
<br>

The results of the testing and the assests can be found in these directories:
* <i>test_results</i>: The videos of the output generated by the model used for testing.
* <i>test_results_logs</i>: The log files generated during testing.
* <i>assets</i>: The images/videos used for testing.

Note: More details of the testing can be found in the Testinf Report.

## Training the Model
The notebooks and preprocessed dataset can be found in the directory ```AR_Model_Training```. The following are the resources:
* <i>generate_pose_dataset.py</i>: The notebook used to preprocess the data.
* <i>AR_ModelTraining_LSTM.py</i>: The notebook used to train the model with the preprocessed data.
* <i>PremadeDataset.py</i>: The preprocessed data that can be used for training the model.

